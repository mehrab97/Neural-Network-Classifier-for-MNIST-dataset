{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST data is a combination of a lot of images. These have digits in them from 0 to 9. Every image has 1 digit\n",
    "# from 0 to 9. Our task is to build a classifier, a neural network which is going to predict which digit\n",
    "# the given image is going to contain.\n",
    "#Within tensor flow, there is example.tutorials from which one can load the dataset. There is one small problem with \n",
    "#that. It is getting deprecated. Sklearn has a way to load mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-0eda2f9c2d4a>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fc902d5a4a8>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fc8ea01aa20>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fc8ea01abe0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000, 10))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape, mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape, mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]]),\n",
       " array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels, mnist.test.labels #one-hot encoded, all zeros except one place where value is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image=mnist.train.images[0] #it is a flattened image\n",
    "#so convert to an np array\n",
    "first_image=np.array(first_image,dtype='float')\n",
    "first_image=first_image.reshape((28,28))\n",
    "plt.imshow(first_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOAklEQVR4nO3de4xc9XnG8eex8aUxkNg4dozjJpRLCqWKSbcmNYjQ0BAulUyUpsKilKZuHEXQJhVRQtILKG0lC0JIq0REm2BhKJBSBQsL0TSWhURRUuqFOMaOHcCuC77ILnKCDQFf3/6xQ7WYPb9Zz5y52O/3I41m5rxz5rwa7bPnzPzmzM8RIQDHv3G9bgBAdxB2IAnCDiRB2IEkCDuQxAnd3NhET4rJmtLNTQKpvK5XtT/2ebRaW2G3fZmkf5Q0XtJ3ImJJ6fGTNUXn+5J2Ngmg4MlYVVlr+TDe9nhJ35R0uaRzJC20fU6rzwegs9p5zz5P0vMRsTki9kv6rqQF9bQFoG7thH22pBdH3N/aWPYmthfbHrI9dED72tgcgHa0E/bRPgR4y3dvI2IwIgYiYmCCJrWxOQDtaCfsWyXNGXH/3ZK2t9cOgE5pJ+yrJZ1p+zTbEyVdLWlFPW0BqFvLQ28RcdD2DZL+XcNDb0sjYn1tnQGoVVvj7BHxqKRHa+oFQAfxdVkgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkujqlM3oPz6h/Cfwyys/UKxPv/G/i/WHzlhZWVv12vjiurdfflWxfujZTcU63ow9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7cq888qvF+mO/eWdbz38gqmsXTT5UXPemC2cU69MYZz8qbYXd9hZJeyUdknQwIgbqaApA/erYs/9uRLxUw/MA6CDeswNJtBv2kPQD20/ZXjzaA2wvtj1ke+iA9rW5OQCtavcw/oKI2G57hqSVtjdGxOMjHxARg5IGJelkTyt8XAOgk9ras0fE9sb1LknLJc2roykA9Ws57Lan2D7pjduSLpW0rq7GANSrncP4mZKW237jee6PiO/X0hWOzrjq88I33fbbxVXXnvtPxfoVGz9erB+8dWaxPq4w0P79eweL6+756KvF+rSlxTKO0HLYI2KzpPfX2AuADmLoDUiCsANJEHYgCcIOJEHYgSQ4xfU48MrHq0823HD1N4vr/sbjnyrWT1v4k2J9ol4s1sefMq2yds+e2cV1US/27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsx4BxJ51UrH9lyXcqa9du+Uhx3dM/+bNi/XCx2pxPnFJZ++OTtxXXvbXNbePN2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMsx8DPL78P/miyfsra1/YPb247vTXn22pp2444YTylM7j3/H2Yj0OVX9L4PDevS31dCxjzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOfgwojRdL0tr95fHoY9WaD95TfsD6crl0Lv/PL2ihoWNc0z277aW2d9leN2LZNNsrbT/XuJ7a2TYBtGssh/F3S7rsiGU3SVoVEWdKWtW4D6CPNQ17RDwuafcRixdIWta4vUzSVTX3BaBmrX5ANzMidkhS43pG1QNtL7Y9ZHvogPa1uDkA7er4p/ERMRgRAxExMEGTOr05ABVaDftO27MkqXG9q76WAHRCq2FfIem6xu3rJD1cTzsAOqXpOLvtByRdLGm67a2Sbpa0RNKDthdJekHSJzrZZHbNzr2+ZvWiytrdA3cX1/3KzMuL9UM72ztoe/Xcd7W1fsnOQ68V65sH31dZm6of1d1O32sa9ohYWFG6pOZeAHQQX5cFkiDsQBKEHUiCsANJEHYgCU5xPQ6M/3H1lM6/1eRUTk+c2Na2x02eXKy/4wsvtPzcLx9+vVj/gy99vlifel++4bUS9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7MeBWT8qjEffUF5306fmFOvv+dutxfrmvz6vWF93xjfKDRRc+g/lcfR3Mo5+VNizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLMfByau2VRZm//jqh8HHjb0p3cU6zdfOb9Y/9b024r1nx92Ze38R/6yuO7Z95fnZD4+J6ruHPbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zHgUO/eLm69sg5xXUnnTehWF/yrtVNtv4rxeryV6dV1s76zH8V12UcvV5N9+y2l9reZXvdiGW32N5me03jckVn2wTQrrEcxt8t6bJRlt8REXMbl0frbQtA3ZqGPSIel7S7C70A6KB2PqC7wfbaxmH+1KoH2V5se8j20AHta2NzANrRatjvlHS6pLmSdki6veqBETEYEQMRMTBBk1rcHIB2tRT2iNgZEYci4rCkb0uaV29bAOrWUthtzxpx92OS1lU9FkB/aDrObvsBSRdLmm57q6SbJV1se66kkLRF0qc72COaGHfur1fW5i96uoudvNXfDV5TWTtVP+xiJ2ga9ogY7dcP7upALwA6iK/LAkkQdiAJwg4kQdiBJAg7kASnuB4DDl84t1h/7W+qT3G949TODm/9/sYFxfrsr1efxhp1N4Mi9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7H0g5r+/WL/9n79VrJ89ofrnoJ9q8ktg1zx8fbH+Rx/+j2J928tvL9ZnH9xabgBdw54dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0PbPmL8pndpXF0SXrwlRmVtfs/fH5x3TO2/Wex/tDy8ncAzpq+q1j/5YSJlbU4sL+4LurFnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcvQ8MzHmxrfWnjKs+af0X8+cU1z3xX7c3qZ9crP/LbfcW67/30c9U1iY/Uv2b8qhf0z277Tm2H7O9wfZ6259tLJ9me6Xt5xrXUzvfLoBWjeUw/qCkGyPibEkflHS97XMk3SRpVUScKWlV4z6APtU07BGxIyKebtzeK2mDpNmSFkha1njYMklXdapJAO07qg/obL9X0nmSnpQ0MyJ2SMP/ECSN+gVt24ttD9keOqAmP4gGoGPGHHbbJ0r6nqTPRcSesa4XEYMRMRARAxM0qZUeAdRgTGG3PUHDQb8vIh5qLN5pe1ajPktS+fQnAD3VdOjNtiXdJWlDRHxtRGmFpOskLWlcP9yRDhPY8NLMYn39qQeL9SvfVj1l8+Vf/0Zx3e1fLb+1Wr53zAdxo9r2ofGVtdMfaeupcZTGMs5+gaRrJT1je01j2Zc1HPIHbS+S9IKkT3SmRQB1aBr2iHhCkivKl9TbDoBO4euyQBKEHUiCsANJEHYgCcIOJMEprn1gxoKNxfqX5n6yWN94w9sqa4vmPVFc94unrC/W/3zqc8U6jh3s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZjwGH1/y0WD/rz6prPzzl1PK6f39Rsf75D/1bsX735t8p1t93547KWvksfdSNPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOGI6NrGTva0ON/8IC3QKU/GKu2J3aP+GjR7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IomnYbc+x/ZjtDbbX2/5sY/kttrfZXtO4XNH5dgG0aiw/XnFQ0o0R8bTtkyQ9ZXtlo3ZHRHy1c+0BqMtY5mffIWlH4/Ze2xskze50YwDqdVTv2W2/V9J5kp5sLLrB9lrbS21PrVhnse0h20MHtK+tZgG0bsxht32ipO9J+lxE7JF0p6TTJc3V8J7/9tHWi4jBiBiIiIEJmlRDywBaMaaw256g4aDfFxEPSVJE7IyIQxFxWNK3Jc3rXJsA2jWWT+Mt6S5JGyLiayOWzxrxsI9JWld/ewDqMpZP4y+QdK2kZ2yvaSz7sqSFtudKCklbJH26Ix0CqMVYPo1/QtJo58c+Wn87ADqFb9ABSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS6OqUzbb/V9L/jFg0XdJLXWvg6PRrb/3al0Rvraqzt/dExDtHK3Q17G/ZuD0UEQM9a6CgX3vr174kemtVt3rjMB5IgrADSfQ67IM93n5Jv/bWr31J9NaqrvTW0/fsALqn13t2AF1C2IEkehJ225fZ/pnt523f1IseqtjeYvuZxjTUQz3uZantXbbXjVg2zfZK2881rkedY69HvfXFNN6FacZ7+tr1evrzrr9ntz1e0rOSPiJpq6TVkhZGxE+72kgF21skDUREz7+AYfsiSa9Iuicizm0su1XS7ohY0vhHOTUivtgnvd0i6ZVeT+PdmK1o1shpxiVdJelP1MPXrtDXH6oLr1sv9uzzJD0fEZsjYr+k70pa0IM++l5EPC5p9xGLF0ha1ri9TMN/LF1X0VtfiIgdEfF04/ZeSW9MM97T167QV1f0IuyzJb044v5W9dd87yHpB7afsr24182MYmZE7JCG/3gkzehxP0dqOo13Nx0xzXjfvHatTH/erl6EfbSppPpp/O+CiPiApMslXd84XMXYjGka724ZZZrxvtDq9Oft6kXYt0qaM+L+uyVt70Efo4qI7Y3rXZKWq/+mot75xgy6jetdPe7n//XTNN6jTTOuPnjtejn9eS/CvlrSmbZPsz1R0tWSVvSgj7ewPaXxwYlsT5F0qfpvKuoVkq5r3L5O0sM97OVN+mUa76ppxtXj167n059HRNcvkq7Q8CfymyT9VS96qOjr1yT9pHFZ3+veJD2g4cO6Axo+Ilok6RRJqyQ917ie1ke93SvpGUlrNRysWT3q7UINvzVcK2lN43JFr1+7Ql9ded34uiyQBN+gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/g8T0hnr7IElEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image=mnist.train.images[200] #it is a flattened image\n",
    "#so convert to an np array\n",
    "first_image=np.array(first_image,dtype='float')\n",
    "first_image=first_image.reshape((28,28))\n",
    "plt.imshow(first_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each of the image would be 784 sized.Input layer will have 784 entries. Output layer will have 10 units since we \n",
    "# have 10 possible values of the output. Suppose we have two hidden layers. For the number of units in the hidden\n",
    "# layer, we will generally keep it around the same order as the inpu layer (around 100-2000). We can explore.\n",
    "# Say we keep 256 units in both the hidden layers. There will be biases as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'random_normal_1:0' shape=(1, 2) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random_normal([1,2]) #need to give shape in a square bracket\n",
    "#Hasn't been executed yet. Run it in a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1403996  1.8491718]]\n"
     ]
    }
   ],
   "source": [
    "#Running in a session\n",
    "with tf.Session() as sess:\n",
    "    print(tf.random_normal([1,2]).eval()) #works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to initialise the weights with some random values so we will use tf.Variable for them\n",
    "n_input=784 #no of units in input layer\n",
    "n_hidden1=256\n",
    "n_hidden2=256\n",
    "n_classes=10 #output units\n",
    "\n",
    "#Create weights and biases\n",
    "#We create a weights dictionary where the first key is hidden 1 and the values are the weights associated with them\n",
    "#Weights are 2-D\n",
    "weights={'h1':tf.Variable(tf.random_normal([n_input,n_hidden1])),\n",
    "        'h2':tf.Variable(tf.random_normal([n_hidden1,n_hidden2])),\n",
    "        'out':tf.Variable(tf.random_normal([n_hidden2,n_classes]))} #from a normal distribution values are randomly chosen\n",
    "\n",
    "#Biases are 1-D\n",
    "biases={'h1':tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'h2':tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'out':tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Propagation\n",
    "def forward_propagation(x,weights,biases):\n",
    "    #doing matrix multiplication of weights at h1 layer and input x and adding the bias\n",
    "    #This gives the net input at layer1\n",
    "    in_layer1=tf.add(tf.matmul(x,weights['h1']),biases['h1'])\n",
    "    \n",
    "    #layer1 output using relu activation function\n",
    "    out_layer1=tf.nn.relu(in_layer1)\n",
    "    \n",
    "    #input of layer2\n",
    "    in_layer2=tf.add(tf.matmul(out_layer1,weights['h2']),biases['h2'])\n",
    "    \n",
    "    #layer2 output using relu activation function\n",
    "    out_layer2=tf.nn.relu(in_layer2)\n",
    "    \n",
    "    #overall output\n",
    "    output=tf.add(tf.matmul(out_layer2,weights['out']),biases['out'])\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_2' with dtype float and shape [?,784]\n\t [[node Placeholder_2 (defined at /Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'Placeholder_2':\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-db4aa13dedc1>\", line 3, in <module>\n    x=tf.placeholder(\"float\",[None,n_input]) #None as no of images would be different in case of training & testing\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\", line 2619, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 6669, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float and shape [?,784]\n\t [[{{node Placeholder_2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-db4aa13dedc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#To initialize the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mpredictions_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float and shape [?,784]\n\t [[node Placeholder_2 (defined at /Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'Placeholder_2':\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-37-db4aa13dedc1>\", line 3, in <module>\n    x=tf.placeholder(\"float\",[None,n_input]) #None as no of images would be different in case of training & testing\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\", line 2619, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 6669, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/Users/shabeggill/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "#need to pass x as a tensor object\n",
    "#x would be sometimes training data and sometimes testing data\n",
    "x=tf.placeholder(\"float\",[None,n_input]) #None as no of images would be different in case of training & testing\n",
    "#We know how many columns/features each image has (n_input i.e. 784)\n",
    "\n",
    "y=tf.placeholder(tf.int32,[None,n_classes]) #for each image, my output label would be a 10 sized vector\n",
    "\n",
    "#Finding predictions and accuracy without optimization\n",
    "pred=forward_propagation(x,weights,biases)\n",
    "\n",
    "#Once I have the predictions (size 10000*10), for each prediction we find the maximum value and the index at which\n",
    "#the maximum value is happening.\n",
    "predictions=tf.argmax(pred,axis=1) #index at which the maximum is happening. Need to find the argmax among the columns\n",
    "#For each row, need to find this argmax. Axis=1 refers to columns\n",
    "\n",
    "correct_labels=tf.argmax(y,1)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) #To initialize the variables\n",
    "predictions_eval=sess.run(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions=tf.equal(predictions,correct_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 9, 9, ..., 8, 8, 8])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get an error above since x is a placeholder whose value hasn't been passed yet\n",
    "predictions_eval=sess.run(predictions,feed_dict={x:mnist.test.images})\n",
    "predictions_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 9, 9, ..., 8, 8, 8]),\n",
       " array([7, 2, 1, ..., 4, 5, 6]),\n",
       " array([False, False, False, ..., False, False, False]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding predictions_eval,correct_predictions and correct_labels_eval in case of testing data\n",
    "predictions_eval,correct_labels_eval,correct_pred_eval=sess.run([predictions,correct_labels,correct_predictions],\n",
    "                                              feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "predictions_eval,correct_labels_eval,correct_pred_eval\n",
    "\n",
    "#Wherever you got a True--> Correct Prediction\n",
    "#Wherever you got a False--> Incorrect Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "881"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred_eval.sum() #In case of testing data\n",
    "#Gives the number of times the predictions are correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4702"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding predictions_eval,correct_predictions and correct_labels_eval in case of training data\n",
    "predictions_eval,correct_labels_eval,correct_pred_eval=sess.run([predictions,correct_labels,correct_predictions],\n",
    "                                              feed_dict={x:mnist.train.images, y:mnist.train.labels})\n",
    "predictions_eval,correct_labels_eval,correct_pred_eval\n",
    "\n",
    "correct_pred_eval.sum() #in case of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'softmax_cross_entropy_with_logits_sg_1/Reshape_2:0' shape=(?,) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cost Function\n",
    "#To find the cross entrop cross, use softmax\n",
    "tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the optimizer\n",
    "#The inbuilt optimizer will reduce the cost by changing the weights. It will find the gradients and change the\n",
    "# weights so that the cost reduces over time.\n",
    "\n",
    "x=tf.placeholder(\"float\",[None,n_input])\n",
    "y=tf.placeholder(tf.int32,[None,n_classes])\n",
    "pred=forward_propagation(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We're going to take the mean of the values, since if we have 10000 images, we don't want 10000 sized array\n",
    "#And for each image there are 1 labels\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "\n",
    "#Now we need to optimize this cosy by changing the weights. We don't need to write the backpropagation code\n",
    "#by ourselves. We will use an inbuilt optimizer which will take this cost function, figure out what all\n",
    "# variables this cost is dependant on and change those weights to optimize on the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize=optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1853.7163"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "c=sess.run(cost,feed_dict={x:mnist.train.images,y:mnist.train.labels})\n",
    "c #Haven't optimized anything here, haven't run the optimizer, just finding the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1853.7163"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the optimze as well to optimize the cost\n",
    "c,_=sess.run([cost,optimize],feed_dict={x:mnist.train.images,y:mnist.train.labels}) #will be 2 variables now since\n",
    "#we have passed two things here\n",
    "c #Cost lowers on running the cell multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How does the optimizer work\n",
    "# So how does the optimizer know what all variables to change. We had weights, n_input, biases, x, y\n",
    "#By default all the variables that you create have a property trainable=True\n",
    "# The optimizer finds out what all variables exist which have trainable=true and it's going to find gradient\n",
    "# with respect to all of them and change the values for all of them to try and optimize the cost\n",
    "#If you want, you can even say that you don't ant to train on weights. If you don't want to train on h1,\n",
    "#just pass trainable=False for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The optimzer finds out what all variables the cost depends upon. If cost doesn't depend upon a variable, it's \n",
    "#not going to change that variable just because it's trainable. Now out of all the variables that the cost depends\n",
    "#upo if any has trainable=False, the optimzer won't chnage that variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1236.3419\n",
      "846.6372\n",
      "621.8154\n",
      "502.3223\n",
      "389.07092\n",
      "303.49942\n",
      "261.76602\n",
      "225.63365\n",
      "200.18091\n",
      "185.30444\n",
      "171.87585\n",
      "156.47049\n",
      "140.92676\n",
      "127.37764\n",
      "116.44542\n",
      "108.10843\n",
      "102.25564\n",
      "98.249146\n",
      "94.765915\n",
      "91.05993\n",
      "86.92619\n",
      "82.45847\n",
      "77.975365\n",
      "73.93198\n",
      "70.61224\n"
     ]
    }
   ],
   "source": [
    "#Running Multiple Iterations\n",
    "\n",
    "for i in range(25):\n",
    "    c,_=sess.run([cost,optimize],feed_dict={x:mnist.train.images,y:mnist.train.labels})\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8511"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=tf.argmax(pred,axis=1)\n",
    "correct_labels=tf.argmax(y,1)\n",
    "correct_predictions=tf.equal(predictions,correct_labels)\n",
    "predictions_eval,correct_labels_eval,correct_pred_eval=sess.run([predictions,correct_labels,correct_predictions],\n",
    "                                              feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "correct_pred_eval.sum() #Sum of instances where predictions are correct\n",
    "#Around 85% accuracy now with optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24917.090491890907\n",
      "4717.542796625441\n",
      "2519.2641644056503\n",
      "1713.7236086613016\n",
      "1454.7252786558424\n",
      "1218.169158488693\n",
      "1127.8666792290992\n",
      "976.1358631873157\n",
      "1041.0333706185477\n",
      "719.1006587854854\n",
      "680.0983523169681\n",
      "612.6682076710088\n",
      "584.0844628283265\n",
      "456.3488741140262\n",
      "428.42722055058437\n",
      "368.4308195838761\n",
      "376.7526386510505\n",
      "368.2062780051944\n",
      "234.00313719711977\n",
      "263.88872847072054\n",
      "261.4197340806405\n",
      "207.23988392342076\n",
      "224.0663111453198\n",
      "204.8215819084576\n",
      "141.61795510834511\n"
     ]
    }
   ],
   "source": [
    "#Batch Gradient Descent\n",
    "\n",
    "#Right now we are running the above code 25 times and each time we are taking the complete data as x and y\n",
    "#we'll change it a bit. We'll run it 25 times but we'll decide a batch size say 100. 55000 %100 = 550\n",
    "# We will have another loop which will run 550 times (550 batches with each batch having 100 images)\n",
    "\n",
    "#For every iteration, you won't pass the complete set of images, you will pass small small batches\n",
    "#Let's say the batch size is 100\n",
    "\n",
    "batch_size=100\n",
    "for i in range(25):\n",
    "    #mnist.train.num_examples will tell the number of examples in training data\n",
    "    num_batches=int(mnist.train.num_examples/batch_size) #550\n",
    "    total_cost=0\n",
    "    for j in range(num_batches): #550 times\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size) #It will give the next 100 images/batch and so on\n",
    "        c,_=sess.run([cost,optimize],feed_dict={x:batch_x,y:batch_y}) #passing batches and not the complete data\n",
    "        total_cost+=c\n",
    "    print(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9595"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=tf.argmax(pred,axis=1)\n",
    "correct_labels=tf.argmax(y,1)\n",
    "correct_predictions=tf.equal(predictions,correct_labels)\n",
    "predictions_eval,correct_labels_eval,correct_pred_eval=sess.run([predictions,correct_labels,correct_predictions],\n",
    "                                              feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "correct_pred_eval.sum() #We get 95.95% accuracy here when we use batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
